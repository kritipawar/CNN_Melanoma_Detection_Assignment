{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df4eEEArGVSH"
   },
   "source": [
    "## Problem Statement\n",
    "\n",
    "To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution that can evaluate images and alert dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppss92lzHVsG"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-6eoygsGcan"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "from IPython.display import display\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "# from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXStv9S3fqK3"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Set the warning filter to \"ignore\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nthTLpvvHxjI",
    "outputId": "6236286d-c67e-4aef-e978-4cbec319228a"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "#Unzipping compressed Input File\n",
    "with zipfile.ZipFile('CNN_assignment.zip','r') as f:\n",
    "    f.extractall('input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JqLmqe2IFqZ",
    "outputId": "7041a2bd-ddde-4ab0-cda8-492daf73f5c1"
   },
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "data_dir_train = pathlib.Path(\"input/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\")\n",
    "data_dir_test = pathlib.Path('input/Skin cancer ISIC The International Skin Imaging Collaboration/Test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgv6J-kOcnFE"
   },
   "source": [
    "### Load using keras.preprocessing**\n",
    "\n",
    "Let's load these images off disk using the helpful image_dataset_from_directory utility.\n",
    "\n",
    "### Create a dataset\n",
    "\n",
    "Define some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0wxSlHHbfv_"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1BCxbtmcxgx",
    "outputId": "a392a2e6-4bad-43e1-9498-404a5fa0cb98"
   },
   "outputs": [],
   "source": [
    "## train dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74NKianIdDJb",
    "outputId": "2aae75da-85ae-4365-ef3f-2bdcb7dd00f6"
   },
   "outputs": [],
   "source": [
    "## train dataset\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bhO5JlSdX1O",
    "outputId": "a77a7cc5-0332-450f-f802-152ccfbf7e32"
   },
   "outputs": [],
   "source": [
    "# To list out all the classes of skin cancer and store them in a list, you can use the class_names attribute of the train_ds dataset. These class names correspond to the directory names in alphabetical order.\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "2T5RiO3FddV5",
    "outputId": "e307dd52-30ce-498e-8b8b-c238fe53c2d9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "# Create a 3x3 grid for visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Iterate through different lesion types\n",
    "for lesion_type in range(9):\n",
    "    class_path = glob.glob(os.path.join(data_dir_train, class_names[lesion_type], '*'))\n",
    "    \n",
    "    # Check if there are any images in this class\n",
    "    if class_path:\n",
    "        img = PIL.Image.open(str(class_path[0]))\n",
    "        ax = plt.subplot(3, 3, lesion_type + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_names[lesion_type])\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        # If there are no images in this class, display a placeholder or message\n",
    "        ax = plt.subplot(3, 3, lesion_type + 1)\n",
    "        plt.text(0.5, 0.5, \"No Image\", fontsize=12, ha='center')\n",
    "        plt.title(class_names[lesion_type])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzYvB7WKeZLu"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Simple CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HxO9P6QhsJO",
    "outputId": "8247d73f-e1fa-4d0a-e9ee-788cb5a9be23"
   },
   "outputs": [],
   "source": [
    "# Define the number of classes in your dataset\n",
    "num_classes = 9  #  number of classes\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1.0 / 255, input_shape=(180, 180, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xhAbwnniF7U",
    "outputId": "b02c5c24-1449-4dc6-f62d-2fb1e5edb425"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiNP9VQjiMH5"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's what these indicators mean:\n",
    "\n",
    "**Low Validation Accuracy:** This suggests that the model is not performing well on data it hasn't seen during training. It's not generalizing the patterns it learned from the training data to new, unseen data.\n",
    "\n",
    "**High Validation Loss:** A high validation loss means that the model's predictions are far off from the true labels on the validation dataset. It's making significant errors on the validation data.\n",
    "\n",
    "**Overfitting** can happen for several reasons, including:\n",
    "\n",
    "**Complex Model:** The model may be too complex for the data, allowing it to memorize the training data rather than learning meaningful patterns.\n",
    "\n",
    "**Not Enough Data:** With a small dataset, the model may not have enough examples to learn generalizable patterns. It ends up fitting noise rather than the underlying data distribution.\n",
    "\n",
    "**Training for Too Long:** If you train the model for too many epochs, it may start memorizing the training data instead of generalizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oHKXE8sjkhQ"
   },
   "source": [
    "### To address overfitting, you can consider the following techniques:\n",
    "\n",
    "**Regularization:** Add dropout layers or L1/L2 regularization to reduce overfitting.\n",
    "\n",
    "**More Data:** Collect more data if possible. More data can help the model learn generalizable patterns.\n",
    "\n",
    "**Simpler Model:** Use a simpler architecture that is less likely to overfit the data.\n",
    "\n",
    "**Early Stopping:** Monitor the validation loss during training and stop training when it starts to increase. This prevents the model from overfitting.\n",
    "\n",
    "**Data Augmentation:** Apply data augmentation techniques to artificially increase the size of your training dataset.\n",
    "\n",
    "**Hyperparameter Tuning:** Adjust hyperparameters such as learning rate, batch size, and layer sizes to find the best model for your data.\n",
    "\n",
    "**Cross-Validation:** Use techniques like k-fold cross-validation to get a better estimate of your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model2 with Dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will choose dropout layers\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = 9  # Replace with the actual number of classes\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1.0 / 255, input_shape=(180, 180, 3)),  # Normalize pixel values\n",
    "\n",
    "    # Add Convolutional layers with Dropout\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the output from Convolutional layers\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Add Dense layers with Dropout\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Add a dropout layer with a dropout rate of 0.5\n",
    "    layers.Dense(num_classes, activation='softmax')  # Use 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **Adam optimizer** is a versatile choice that works well for many deep learning tasks, and **sparse_categorical_crossentropy** is a suitable loss function for multi-class classification when labels are provided as integers. These choices are often used as starting points, and you can fine-tune hyperparameters and explore other optimizers and loss functions based on the specific characteristics of your dataset and problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model3 with Dropout and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.5),\n",
    "    layers.RandomContrast(0.5),\n",
    "    layers.RandomBrightness(0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing how your augmentation strategy works for one instance of training image.\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_image = data_augmentation(img)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_image.numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[1]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Dropout layer as there is an evidence of overfitting\n",
    "\n",
    "dropout_conv=0.05\n",
    "dropout_dense=0.25\n",
    "\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(img_height, img_width, 3)),\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),  \n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(dropout_conv),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_dense),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here, note: train your model for 20 epochs\n",
    "epochs = 20 # As specified in the project pipeline\n",
    "history = model3.fit(\n",
    "  train_ds,\n",
    "  validation_data = val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, the model, which includes data augmentation and dropout layers, does not exhibit improved performance on the training data; in fact, it performs noticeably worse. This suggests that the model is experiencing underfitting, where it struggles to capture the underlying patterns in the training data, leading to poor training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the distribution of classes in the training dataset.\n",
    "#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the class distribution\n",
    "class_distribution = {}\n",
    "\n",
    "# Iterate through the training dataset and count the samples for each class\n",
    "for _, labels in train_ds:\n",
    "    for label in labels.numpy():\n",
    "        if label in class_distribution:\n",
    "            class_distribution[label] += 1\n",
    "        else:\n",
    "            class_distribution[label] = 1\n",
    "\n",
    "# Print the class distribution with actual label names\n",
    "for class_label, count in class_distribution.items():\n",
    "    class_name = class_names[class_label]  # Get the actual label name\n",
    "    print(f\"Class '{class_name}': {count} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** Write your findings here: \n",
    "#### - Which class has the least number of samples?\n",
    "seborrheic keratosis has least number of sample.\n",
    "#### - Which classes dominate the data in terms proportionate number of samples?\n",
    "pigmented benign keratosis & melanoma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Rectifying the class imbalance\n",
    "#### **Context:** Using a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `Augmentor`, the following general procedure is followed:\n",
    "\n",
    "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
    "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
    "3. Execute these operations by calling the `Pipeline’s` `sample()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "\n",
    "# Create a PosixPath object representing the path to your training dataset\n",
    "path_to_training_dataset=str(data_dir_train)\n",
    "\n",
    "# Iterate through the class names\n",
    "for class_name in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset+'\\\\'+ class_name)  # Use the / operator to join paths\n",
    "    p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500)  # Add 500 samples per class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = [x for x in glob.glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob.glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "lesion_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model4 with Data Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training set\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = \"training\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation set\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = \"validation\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model \n",
    "\n",
    "num_classes = 9\n",
    "\n",
    "model4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile model \n",
    "\n",
    "## your code goes here\n",
    "model4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "history = model4.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=0  # Set verbose to 0 to suppress training output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:**  Analyze your results here. Did you get rid of underfitting/overfitting? Did class rebalance help?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The results from the model with dataset augmentation have shown significant improvement over previous models, achieving a training accuracy of 0.94 at 20 epochs and a validation accuracy of 0.84. However, there are indications of overfitting, as seen by the large fluctuations in the validation loss. To address this issue, we can implement a learning rate scheduler to reduce the learning rate when an accuracy of 0.8 is reached, which may lead to further improvements.\n",
    "\n",
    "Key takeaways and suggestions:\n",
    "\n",
    "1. **Overfitting**: The model is still overfitting the data, as indicated by the fluctuations in the validation loss. To mitigate overfitting, consider adding more layers, neurons, or introducing dropout layers. This can help the model generalize better.\n",
    "\n",
    "2. **Hyperparameter Tuning**: The model's performance can be further improved through hyperparameter tuning. Experiment with different learning rates, batch sizes, and optimizer choices to find the best configuration for your dataset.\n",
    "\n",
    "3. **Learning Rate Scheduler**: Implement a learning rate scheduler that reduces the learning rate when the accuracy reaches 0.8. This can help the model converge more steadily and potentially reach a better optimum.\n",
    "\n",
    "By addressing these issues and fine-tuning the model, you can achieve even better results and a more robust model for skin cancer detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
